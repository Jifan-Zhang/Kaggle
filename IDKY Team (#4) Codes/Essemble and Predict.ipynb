{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp \"/notebooks/storage/Manual Model.h5\" \"/notebooks/storage/2020-04-11(0.546).h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! cp \"/notebooks/storage/2020-04-06(0.58).h5\" \"/notebooks/storage/Manual Model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5000 [00:00<09:27,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded h5 model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [04:03<00:00, 20.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model=load_model(\"/storage/2020-04-06(0.58).h5\",compile=False)\n",
    "model.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n",
    "print(\"Successfully loaded h5 model!\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_validate = pd.read_csv(\"/storage/validate.csv\", na_values=['NA', '?'])\n",
    "df_validate['filename']=\"clips-\"+df_validate[\"id\"].astype(str)+\".png\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGES_DIR = \"/storage/clips\"\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(5000)):\n",
    "    arr=np.expand_dims(np.array(Image.open(f\"/storage/clips/clips-{25001+i}.png\"))/255, 0)\n",
    "    df.loc[i+25001,\"clip_count\"]=model.predict(arr)\n",
    "df[\"clip_count\"]=df[\"clip_count\"].apply(lambda x: 75 if x>75 else x)\n",
    "df=df.reset_index()\n",
    "df.columns=[\"id\",\"clip_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/notebooks/submit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded h5 model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [05:19<00:00, 15.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45001</th>\n",
       "      <td>68.247749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45002</th>\n",
       "      <td>40.110317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45003</th>\n",
       "      <td>41.237000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45004</th>\n",
       "      <td>38.798252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45005</th>\n",
       "      <td>18.474697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>35.309082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>53.150887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>71.147865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>23.043373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>35.664646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       clip_count\n",
       "45001   68.247749\n",
       "45002   40.110317\n",
       "45003   41.237000\n",
       "45004   38.798252\n",
       "45005   18.474697\n",
       "...           ...\n",
       "49996   35.309082\n",
       "49997   53.150887\n",
       "49998   71.147865\n",
       "49999   23.043373\n",
       "50000   35.664646\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model=load_model(\"/storage/2020-04-06(0.58).h5\",compile=False)\n",
    "model.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n",
    "print(\"Successfully loaded h5 model!\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "df=pd.DataFrame()\n",
    "for i in tqdm(range(5000)):\n",
    "    arr=np.expand_dims(np.array(Image.open(f\"/storage/clips/clips-{45001+i}.png\"))/255, 0)\n",
    "    df.loc[i+45001,\"clip_count\"]=model.predict(arr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5787314589089702"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"/notebooks/test_prediction.csv\")\n",
    "df.columns=[\"id\",\"clip_count\"]\n",
    "df[\"clip_count\"]=df[\"clip_count\"].apply(lambda x: 75 if x>75 else x)\n",
    "df[\"decimal\"]=df[\"clip_count\"]-df[\"clip_count\"].astype(\"int\")\n",
    "df[\"integer\"]=df[\"clip_count\"].astype(\"int\")\n",
    "df[\"True count\"]=pd.read_csv(\"/storage/data.csv\")[\"clip_count\"][-5000:].values\n",
    "df[\"error\"]=df[\"True count\"]-df[\"clip_count\"]\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "display(mean_squared_error(df[\"clip_count\"],df[\"True count\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clip_count\"]=df[\"after decimal\"]+df[\"integer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5865635793156492"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(df[\"clip_count\"],df[\"True count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Three Temporary Best Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clip_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25001</td>\n",
       "      <td>2.034137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25002</td>\n",
       "      <td>47.229285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25003</td>\n",
       "      <td>63.888115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25004</td>\n",
       "      <td>3.408607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25005</td>\n",
       "      <td>44.976323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>29996</td>\n",
       "      <td>31.672199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>29997</td>\n",
       "      <td>54.746607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>29998</td>\n",
       "      <td>61.425887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>29999</td>\n",
       "      <td>4.965807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>30000</td>\n",
       "      <td>31.315255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  clip_count\n",
       "0     25001    2.034137\n",
       "1     25002   47.229285\n",
       "2     25003   63.888115\n",
       "3     25004    3.408607\n",
       "4     25005   44.976323\n",
       "...     ...         ...\n",
       "4995  29996   31.672199\n",
       "4996  29997   54.746607\n",
       "4997  29998   61.425887\n",
       "4998  29999    4.965807\n",
       "4999  30000   31.315255\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1=pd.read_csv(\"/notebooks/submit6.csv\")\n",
    "df2=pd.read_csv(\"/notebooks/submit7.csv\")\n",
    "df3=pd.read_csv(\"/notebooks/submit.csv\")\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df[\"id\"]=df1[\"id\"]\n",
    "df[\"clip_count\"]=(df1[\"clip_count\"]+df2[\"clip_count\"]+df3[\"clip_count\"])/3\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/notebooks/submit8.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test=pd.read_csv(\"/notebooks/test.csv\")\n",
    "test_features=pd.read_csv(\"/notebooks/test_features.csv\").iloc[-5000:,2:]\n",
    "test[\"f1\"]=test_features[\"size\"].values\n",
    "test[\"f2\"]=test_features[\"grey_pixel_number\"].values\n",
    "test[\"f3\"]=test_features[\"50\"].values\n",
    "test.drop([\"True\",\"Unnamed: 0\",\"feature1\"],axis=1,inplace=True)\n",
    "test[\"True\"]=pd.read_csv(\"/notebooks/storage/data.csv\")[-5000:][\"clip_count\"].values\n",
    "test.to_csv(\"/notebooks/test.csv\")\n",
    "\n",
    "\n",
    "final=pd.read_csv(\"/notebooks/final.csv\")\n",
    "submit_features=pd.read_csv(\"/notebooks/submit_features.csv\").iloc[-5000:,2:]\n",
    "final[\"f1\"]=submit_features[\"size\"].values\n",
    "final[\"f2\"]=submit_features[\"grey_pixel_number\"].values\n",
    "final[\"f3\"]=submit_features[\"50\"].values\n",
    "final.to_csv(\"/notebooks/final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [05:11<00:00, 16.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/12 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [04:51<00:00, 17.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/12 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [04:47<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/12 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [04:40<00:00, 17.80it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/12 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [04:49<00:00, 17.26it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/12 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [04:50<00:00, 17.20it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_list=[]\n",
    "for file in os.listdir(\"/storage\"):\n",
    "    if \"0.5\" in file:\n",
    "        model_list.append(file)\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "count=7\n",
    "#final=pd.DataFrame()\n",
    "#final.to_csv(\"/notebooks/test.csv\")\n",
    "#final[\"id\"]=range(45001,50001)\n",
    "#final=final.set_index(\"id\")\n",
    "final=pd.read_csv(\"/notebooks/test.csv\")\n",
    "for file in model_list[6:]:\n",
    "    model=load_model(f\"/storage/{file}\",compile=False)\n",
    "    model.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n",
    "    \n",
    "    for i in tqdm(range(45001,50001)):\n",
    "        arr=np.expand_dims(np.array(Image.open(f\"/storage/clips/clips-{i}.png\"))/255, 0)\n",
    "        final.loc[i,str(count)]=model.predict(arr)[0,0]\n",
    "    final[str(count)]=final[str(count)].apply(lambda x: 75 if x>75 else x)\n",
    "    final.to_csv(\"/notebooks/test.csv\")\n",
    "    print(f\"{count}/12 done.\")\n",
    "    count+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set for XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:22.16201\ttrain-rmse:21.55981\n",
      "[1]\teval-rmse:11.12824\ttrain-rmse:10.85018\n",
      "[2]\teval-rmse:5.65274\ttrain-rmse:5.49184\n",
      "[3]\teval-rmse:2.96067\ttrain-rmse:2.83610\n",
      "[4]\teval-rmse:1.68070\ttrain-rmse:1.53851\n",
      "[5]\teval-rmse:1.12956\ttrain-rmse:0.91251\n",
      "[6]\teval-rmse:0.93938\ttrain-rmse:0.62276\n",
      "[7]\teval-rmse:0.88437\ttrain-rmse:0.49823\n",
      "[8]\teval-rmse:0.86733\ttrain-rmse:0.43782\n",
      "[9]\teval-rmse:0.86369\ttrain-rmse:0.41141\n",
      "[10]\teval-rmse:0.86133\ttrain-rmse:0.39061\n",
      "[11]\teval-rmse:0.86499\ttrain-rmse:0.37599\n",
      "[12]\teval-rmse:0.86457\ttrain-rmse:0.36173\n",
      "[13]\teval-rmse:0.86294\ttrain-rmse:0.35311\n",
      "[14]\teval-rmse:0.86405\ttrain-rmse:0.34546\n",
      "[15]\teval-rmse:0.86110\ttrain-rmse:0.32487\n",
      "[16]\teval-rmse:0.86018\ttrain-rmse:0.32259\n",
      "[17]\teval-rmse:0.85952\ttrain-rmse:0.31043\n",
      "[18]\teval-rmse:0.86256\ttrain-rmse:0.30554\n",
      "[19]\teval-rmse:0.86352\ttrain-rmse:0.28191\n",
      "[20]\teval-rmse:0.86547\ttrain-rmse:0.27337\n",
      "[21]\teval-rmse:0.86340\ttrain-rmse:0.25556\n",
      "[22]\teval-rmse:0.86001\ttrain-rmse:0.25161\n",
      "[23]\teval-rmse:0.85477\ttrain-rmse:0.24053\n",
      "[24]\teval-rmse:0.85783\ttrain-rmse:0.22538\n",
      "[25]\teval-rmse:0.85689\ttrain-rmse:0.22199\n",
      "[26]\teval-rmse:0.85717\ttrain-rmse:0.21982\n",
      "[27]\teval-rmse:0.85762\ttrain-rmse:0.21174\n",
      "[28]\teval-rmse:0.86247\ttrain-rmse:0.20014\n",
      "[29]\teval-rmse:0.86123\ttrain-rmse:0.19315\n",
      "[30]\teval-rmse:0.86254\ttrain-rmse:0.18279\n",
      "[31]\teval-rmse:0.86289\ttrain-rmse:0.17861\n",
      "[32]\teval-rmse:0.86308\ttrain-rmse:0.17707\n",
      "[33]\teval-rmse:0.86461\ttrain-rmse:0.17577\n",
      "[34]\teval-rmse:0.86625\ttrain-rmse:0.16956\n",
      "[35]\teval-rmse:0.86744\ttrain-rmse:0.16106\n",
      "[36]\teval-rmse:0.86956\ttrain-rmse:0.15896\n",
      "[37]\teval-rmse:0.86985\ttrain-rmse:0.15501\n",
      "[38]\teval-rmse:0.86948\ttrain-rmse:0.15100\n",
      "[39]\teval-rmse:0.87010\ttrain-rmse:0.14924\n",
      "[40]\teval-rmse:0.86903\ttrain-rmse:0.14252\n",
      "[41]\teval-rmse:0.86979\ttrain-rmse:0.13775\n",
      "[42]\teval-rmse:0.86974\ttrain-rmse:0.13643\n",
      "[43]\teval-rmse:0.86921\ttrain-rmse:0.13104\n",
      "[44]\teval-rmse:0.86974\ttrain-rmse:0.12996\n",
      "[45]\teval-rmse:0.86908\ttrain-rmse:0.12594\n",
      "[46]\teval-rmse:0.87118\ttrain-rmse:0.12296\n",
      "[47]\teval-rmse:0.87056\ttrain-rmse:0.11727\n",
      "[48]\teval-rmse:0.87062\ttrain-rmse:0.11588\n",
      "[49]\teval-rmse:0.87097\ttrain-rmse:0.11164\n",
      "[50]\teval-rmse:0.87082\ttrain-rmse:0.11009\n",
      "[51]\teval-rmse:0.87101\ttrain-rmse:0.10618\n",
      "[52]\teval-rmse:0.87082\ttrain-rmse:0.10530\n",
      "[53]\teval-rmse:0.87111\ttrain-rmse:0.10214\n",
      "[54]\teval-rmse:0.86977\ttrain-rmse:0.09772\n",
      "[55]\teval-rmse:0.87001\ttrain-rmse:0.09311\n",
      "[56]\teval-rmse:0.87076\ttrain-rmse:0.09085\n",
      "[57]\teval-rmse:0.87085\ttrain-rmse:0.08913\n",
      "[58]\teval-rmse:0.87037\ttrain-rmse:0.08610\n",
      "[59]\teval-rmse:0.87034\ttrain-rmse:0.08578\n",
      "[60]\teval-rmse:0.87052\ttrain-rmse:0.08453\n",
      "[61]\teval-rmse:0.87133\ttrain-rmse:0.08248\n",
      "[62]\teval-rmse:0.87117\ttrain-rmse:0.08178\n",
      "[63]\teval-rmse:0.87124\ttrain-rmse:0.08134\n",
      "[64]\teval-rmse:0.87154\ttrain-rmse:0.07994\n",
      "[65]\teval-rmse:0.87151\ttrain-rmse:0.07944\n",
      "[66]\teval-rmse:0.87243\ttrain-rmse:0.07637\n",
      "[67]\teval-rmse:0.87222\ttrain-rmse:0.07352\n",
      "[68]\teval-rmse:0.87301\ttrain-rmse:0.07000\n",
      "[69]\teval-rmse:0.87299\ttrain-rmse:0.06692\n",
      "[70]\teval-rmse:0.87294\ttrain-rmse:0.06515\n",
      "[71]\teval-rmse:0.87250\ttrain-rmse:0.06331\n",
      "[72]\teval-rmse:0.87280\ttrain-rmse:0.06238\n",
      "[73]\teval-rmse:0.87265\ttrain-rmse:0.06042\n",
      "[74]\teval-rmse:0.87305\ttrain-rmse:0.05880\n",
      "[75]\teval-rmse:0.87349\ttrain-rmse:0.05643\n",
      "[76]\teval-rmse:0.87331\ttrain-rmse:0.05423\n",
      "[77]\teval-rmse:0.87340\ttrain-rmse:0.05214\n",
      "[78]\teval-rmse:0.87356\ttrain-rmse:0.05110\n",
      "[79]\teval-rmse:0.87411\ttrain-rmse:0.04974\n",
      "[80]\teval-rmse:0.87417\ttrain-rmse:0.04914\n",
      "[81]\teval-rmse:0.87393\ttrain-rmse:0.04703\n",
      "[82]\teval-rmse:0.87387\ttrain-rmse:0.04604\n",
      "[83]\teval-rmse:0.87390\ttrain-rmse:0.04496\n",
      "[84]\teval-rmse:0.87356\ttrain-rmse:0.04310\n",
      "[85]\teval-rmse:0.87375\ttrain-rmse:0.04093\n",
      "[86]\teval-rmse:0.87380\ttrain-rmse:0.04054\n",
      "[87]\teval-rmse:0.87384\ttrain-rmse:0.03936\n",
      "[88]\teval-rmse:0.87383\ttrain-rmse:0.03928\n",
      "[89]\teval-rmse:0.87399\ttrain-rmse:0.03886\n",
      "[90]\teval-rmse:0.87435\ttrain-rmse:0.03829\n",
      "[91]\teval-rmse:0.87458\ttrain-rmse:0.03666\n",
      "[92]\teval-rmse:0.87459\ttrain-rmse:0.03587\n",
      "[93]\teval-rmse:0.87451\ttrain-rmse:0.03503\n",
      "[94]\teval-rmse:0.87455\ttrain-rmse:0.03426\n",
      "[95]\teval-rmse:0.87455\ttrain-rmse:0.03327\n",
      "[96]\teval-rmse:0.87445\ttrain-rmse:0.03258\n",
      "[97]\teval-rmse:0.87471\ttrain-rmse:0.03184\n",
      "[98]\teval-rmse:0.87470\ttrain-rmse:0.03150\n",
      "[99]\teval-rmse:0.87479\ttrain-rmse:0.03077\n",
      "[100]\teval-rmse:0.87499\ttrain-rmse:0.02958\n",
      "[101]\teval-rmse:0.87530\ttrain-rmse:0.02912\n",
      "[102]\teval-rmse:0.87532\ttrain-rmse:0.02789\n",
      "[103]\teval-rmse:0.87534\ttrain-rmse:0.02719\n",
      "[104]\teval-rmse:0.87545\ttrain-rmse:0.02656\n",
      "[105]\teval-rmse:0.87543\ttrain-rmse:0.02576\n",
      "[106]\teval-rmse:0.87545\ttrain-rmse:0.02524\n",
      "[107]\teval-rmse:0.87547\ttrain-rmse:0.02516\n",
      "[108]\teval-rmse:0.87548\ttrain-rmse:0.02428\n",
      "[109]\teval-rmse:0.87563\ttrain-rmse:0.02351\n",
      "[110]\teval-rmse:0.87567\ttrain-rmse:0.02273\n",
      "[111]\teval-rmse:0.87567\ttrain-rmse:0.02250\n",
      "[112]\teval-rmse:0.87567\ttrain-rmse:0.02179\n",
      "[113]\teval-rmse:0.87565\ttrain-rmse:0.02157\n",
      "[114]\teval-rmse:0.87565\ttrain-rmse:0.02127\n",
      "[115]\teval-rmse:0.87584\ttrain-rmse:0.02042\n",
      "[116]\teval-rmse:0.87596\ttrain-rmse:0.01989\n",
      "[117]\teval-rmse:0.87590\ttrain-rmse:0.01953\n",
      "[118]\teval-rmse:0.87596\ttrain-rmse:0.01931\n",
      "[119]\teval-rmse:0.87598\ttrain-rmse:0.01890\n",
      "[120]\teval-rmse:0.87607\ttrain-rmse:0.01885\n",
      "[121]\teval-rmse:0.87598\ttrain-rmse:0.01874\n",
      "[122]\teval-rmse:0.87599\ttrain-rmse:0.01845\n",
      "[123]\teval-rmse:0.87601\ttrain-rmse:0.01780\n",
      "[124]\teval-rmse:0.87602\ttrain-rmse:0.01725\n",
      "[125]\teval-rmse:0.87589\ttrain-rmse:0.01658\n",
      "[126]\teval-rmse:0.87598\ttrain-rmse:0.01599\n",
      "[127]\teval-rmse:0.87598\ttrain-rmse:0.01588\n",
      "[128]\teval-rmse:0.87590\ttrain-rmse:0.01531\n",
      "[129]\teval-rmse:0.87595\ttrain-rmse:0.01465\n",
      "[130]\teval-rmse:0.87592\ttrain-rmse:0.01446\n",
      "[131]\teval-rmse:0.87598\ttrain-rmse:0.01406\n",
      "[132]\teval-rmse:0.87599\ttrain-rmse:0.01399\n",
      "[133]\teval-rmse:0.87605\ttrain-rmse:0.01357\n",
      "[134]\teval-rmse:0.87612\ttrain-rmse:0.01307\n",
      "[135]\teval-rmse:0.87613\ttrain-rmse:0.01292\n",
      "[136]\teval-rmse:0.87618\ttrain-rmse:0.01288\n",
      "[137]\teval-rmse:0.87610\ttrain-rmse:0.01263\n",
      "[138]\teval-rmse:0.87615\ttrain-rmse:0.01238\n",
      "[139]\teval-rmse:0.87625\ttrain-rmse:0.01191\n",
      "[140]\teval-rmse:0.87621\ttrain-rmse:0.01165\n",
      "[141]\teval-rmse:0.87616\ttrain-rmse:0.01128\n",
      "[142]\teval-rmse:0.87624\ttrain-rmse:0.01094\n",
      "[143]\teval-rmse:0.87623\ttrain-rmse:0.01065\n",
      "[144]\teval-rmse:0.87619\ttrain-rmse:0.01062\n",
      "[145]\teval-rmse:0.87628\ttrain-rmse:0.01034\n",
      "[146]\teval-rmse:0.87624\ttrain-rmse:0.00999\n",
      "[147]\teval-rmse:0.87621\ttrain-rmse:0.00968\n",
      "[148]\teval-rmse:0.87625\ttrain-rmse:0.00940\n",
      "[149]\teval-rmse:0.87625\ttrain-rmse:0.00931\n",
      "[150]\teval-rmse:0.87626\ttrain-rmse:0.00918\n",
      "[151]\teval-rmse:0.87634\ttrain-rmse:0.00891\n",
      "[152]\teval-rmse:0.87632\ttrain-rmse:0.00861\n",
      "[153]\teval-rmse:0.87632\ttrain-rmse:0.00844\n",
      "[154]\teval-rmse:0.87637\ttrain-rmse:0.00834\n",
      "[155]\teval-rmse:0.87642\ttrain-rmse:0.00809\n",
      "[156]\teval-rmse:0.87643\ttrain-rmse:0.00801\n",
      "[157]\teval-rmse:0.87642\ttrain-rmse:0.00794\n",
      "[158]\teval-rmse:0.87644\ttrain-rmse:0.00772\n",
      "[159]\teval-rmse:0.87643\ttrain-rmse:0.00747\n",
      "[160]\teval-rmse:0.87638\ttrain-rmse:0.00731\n",
      "[161]\teval-rmse:0.87642\ttrain-rmse:0.00719\n",
      "[162]\teval-rmse:0.87642\ttrain-rmse:0.00695\n",
      "[163]\teval-rmse:0.87645\ttrain-rmse:0.00692\n",
      "[164]\teval-rmse:0.87645\ttrain-rmse:0.00677\n",
      "[165]\teval-rmse:0.87646\ttrain-rmse:0.00661\n",
      "[166]\teval-rmse:0.87646\ttrain-rmse:0.00656\n",
      "[167]\teval-rmse:0.87642\ttrain-rmse:0.00622\n",
      "[168]\teval-rmse:0.87641\ttrain-rmse:0.00615\n",
      "[169]\teval-rmse:0.87639\ttrain-rmse:0.00610\n",
      "[170]\teval-rmse:0.87642\ttrain-rmse:0.00591\n",
      "[171]\teval-rmse:0.87643\ttrain-rmse:0.00584\n",
      "[172]\teval-rmse:0.87646\ttrain-rmse:0.00556\n",
      "[173]\teval-rmse:0.87645\ttrain-rmse:0.00554\n",
      "[174]\teval-rmse:0.87644\ttrain-rmse:0.00543\n",
      "[175]\teval-rmse:0.87645\ttrain-rmse:0.00530\n",
      "[176]\teval-rmse:0.87646\ttrain-rmse:0.00517\n",
      "[177]\teval-rmse:0.87644\ttrain-rmse:0.00500\n",
      "[178]\teval-rmse:0.87647\ttrain-rmse:0.00484\n",
      "[179]\teval-rmse:0.87652\ttrain-rmse:0.00478\n",
      "[180]\teval-rmse:0.87650\ttrain-rmse:0.00460\n",
      "[181]\teval-rmse:0.87652\ttrain-rmse:0.00446\n",
      "[182]\teval-rmse:0.87658\ttrain-rmse:0.00432\n",
      "[183]\teval-rmse:0.87658\ttrain-rmse:0.00419\n",
      "[184]\teval-rmse:0.87659\ttrain-rmse:0.00417\n",
      "[185]\teval-rmse:0.87656\ttrain-rmse:0.00404\n",
      "[186]\teval-rmse:0.87657\ttrain-rmse:0.00390\n",
      "[187]\teval-rmse:0.87661\ttrain-rmse:0.00387\n",
      "[188]\teval-rmse:0.87663\ttrain-rmse:0.00376\n",
      "[189]\teval-rmse:0.87663\ttrain-rmse:0.00367\n",
      "[190]\teval-rmse:0.87663\ttrain-rmse:0.00363\n",
      "[191]\teval-rmse:0.87663\ttrain-rmse:0.00357\n",
      "[192]\teval-rmse:0.87663\ttrain-rmse:0.00345\n",
      "[193]\teval-rmse:0.87661\ttrain-rmse:0.00343\n",
      "[194]\teval-rmse:0.87662\ttrain-rmse:0.00333\n",
      "[195]\teval-rmse:0.87663\ttrain-rmse:0.00326\n",
      "[196]\teval-rmse:0.87659\ttrain-rmse:0.00317\n",
      "[197]\teval-rmse:0.87660\ttrain-rmse:0.00311\n",
      "[198]\teval-rmse:0.87664\ttrain-rmse:0.00304\n",
      "[199]\teval-rmse:0.87664\ttrain-rmse:0.00297\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test=pd.read_csv(\"/notebooks/test.csv\")\n",
    "\n",
    "import xgboost as xgb\n",
    "# read in data\n",
    "dtrain = xgb.DMatrix(test.iloc[:4500,2:-1].values,label=test.iloc[:4500,-1].values)\n",
    "dtest = xgb.DMatrix(test.iloc[4500:,2:-1].values,label=test.iloc[4500:,-1].values)\n",
    "param = {'max_depth':10, 'eta':0.5, 'objective':'reg:squarederror',\"silent\":1}\n",
    "evallist = [(dtest,'eval'),(dtrain,'train')]\n",
    "\n",
    "model=xgb.train(param, dtrain,200,evallist) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(test.iloc[:,:-1],\n",
    "                                                  test.iloc[:,-1],\n",
    "                                                  test_size=0.1)\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "model=Sequential()\n",
    "model.add(Dense(12,input_dim=12,activation=\"relu\"))\n",
    "model.add(Dense(6,activation=\"relu\"))\n",
    "#model.add(Dense(3,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"relu\"))\n",
    "model.compile(loss=\"mse\",optimizer=\"adam\")\n",
    "monitor=EarlyStopping(monitor='val_loss',min_delta=1e-3, \n",
    "        patience=20, verbose=0, mode='auto', restore_best_weights=True)\n",
    "model.fit(X_train.values,y_train.values,validation_data=(X_test.values,y_test.values),\n",
    "          epochs=200,callbacks=[monitor],verbose=2)\n",
    "print(\"Done\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(model.predict(X_test.values),y_test),\n",
    "mean_squared_error(X_test.values.mean(axis=1),y_test))\n",
    "\n",
    "model.save(\"/notebooks/Prediction.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"/notebooks/final.csv\")\n",
    "arr=model.predict(df.iloc[:,1:].values)\n",
    "submit=pd.DataFrame({\"id\":range(25001,30001),\"clip_count\":arr.flatten()})\n",
    "submit.to_csv(\"/notebooks/submit10.csv\")\n",
    "\n",
    "df[\"clip_count\"]=df.iloc[:,1:].apply(lambda x: x.mean(),axis=1)\n",
    "df=df.drop(df.columns[1:13],axis=1)\n",
    "df.to_csv(\"/notebooks/submit9.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinary Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>clip_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25001</td>\n",
       "      <td>2.078502</td>\n",
       "      <td>2.048270</td>\n",
       "      <td>2.176548</td>\n",
       "      <td>2.181710</td>\n",
       "      <td>2.171663</td>\n",
       "      <td>2.042809</td>\n",
       "      <td>2.054140</td>\n",
       "      <td>2.218273</td>\n",
       "      <td>1.979649</td>\n",
       "      <td>...</td>\n",
       "      <td>2868</td>\n",
       "      <td>499</td>\n",
       "      <td>65050</td>\n",
       "      <td>2.013689</td>\n",
       "      <td>2.107004</td>\n",
       "      <td>2.010603</td>\n",
       "      <td>2.404801</td>\n",
       "      <td>2.069614</td>\n",
       "      <td>2.198115</td>\n",
       "      <td>2.072007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25002</td>\n",
       "      <td>47.102856</td>\n",
       "      <td>47.471851</td>\n",
       "      <td>47.402054</td>\n",
       "      <td>47.428837</td>\n",
       "      <td>46.916428</td>\n",
       "      <td>46.533054</td>\n",
       "      <td>47.178307</td>\n",
       "      <td>46.916542</td>\n",
       "      <td>46.560528</td>\n",
       "      <td>...</td>\n",
       "      <td>47019</td>\n",
       "      <td>10977</td>\n",
       "      <td>54836</td>\n",
       "      <td>47.192917</td>\n",
       "      <td>46.937836</td>\n",
       "      <td>47.383320</td>\n",
       "      <td>47.509872</td>\n",
       "      <td>48.650318</td>\n",
       "      <td>48.066029</td>\n",
       "      <td>47.003592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25003</td>\n",
       "      <td>63.601151</td>\n",
       "      <td>63.744083</td>\n",
       "      <td>63.498966</td>\n",
       "      <td>64.263016</td>\n",
       "      <td>63.850052</td>\n",
       "      <td>63.831371</td>\n",
       "      <td>63.330708</td>\n",
       "      <td>63.916481</td>\n",
       "      <td>64.481827</td>\n",
       "      <td>...</td>\n",
       "      <td>55200</td>\n",
       "      <td>12753</td>\n",
       "      <td>53104</td>\n",
       "      <td>63.066990</td>\n",
       "      <td>63.650635</td>\n",
       "      <td>63.486897</td>\n",
       "      <td>63.994404</td>\n",
       "      <td>63.896095</td>\n",
       "      <td>63.706322</td>\n",
       "      <td>64.066205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25004</td>\n",
       "      <td>3.402958</td>\n",
       "      <td>3.249214</td>\n",
       "      <td>3.299937</td>\n",
       "      <td>3.176938</td>\n",
       "      <td>3.356996</td>\n",
       "      <td>3.380183</td>\n",
       "      <td>3.544874</td>\n",
       "      <td>3.205535</td>\n",
       "      <td>3.324197</td>\n",
       "      <td>...</td>\n",
       "      <td>3705</td>\n",
       "      <td>627</td>\n",
       "      <td>64924</td>\n",
       "      <td>3.014899</td>\n",
       "      <td>3.257248</td>\n",
       "      <td>3.233060</td>\n",
       "      <td>3.069120</td>\n",
       "      <td>3.185067</td>\n",
       "      <td>3.282437</td>\n",
       "      <td>3.334631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25005</td>\n",
       "      <td>44.893665</td>\n",
       "      <td>45.110535</td>\n",
       "      <td>44.781345</td>\n",
       "      <td>44.324539</td>\n",
       "      <td>44.479763</td>\n",
       "      <td>44.815819</td>\n",
       "      <td>44.842922</td>\n",
       "      <td>44.496338</td>\n",
       "      <td>44.447712</td>\n",
       "      <td>...</td>\n",
       "      <td>45646</td>\n",
       "      <td>10110</td>\n",
       "      <td>55722</td>\n",
       "      <td>44.922932</td>\n",
       "      <td>45.427040</td>\n",
       "      <td>45.568714</td>\n",
       "      <td>43.645378</td>\n",
       "      <td>44.773441</td>\n",
       "      <td>45.163376</td>\n",
       "      <td>44.903638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>29996</td>\n",
       "      <td>31.803255</td>\n",
       "      <td>31.420254</td>\n",
       "      <td>31.000479</td>\n",
       "      <td>31.894354</td>\n",
       "      <td>32.291943</td>\n",
       "      <td>31.517700</td>\n",
       "      <td>31.811995</td>\n",
       "      <td>31.809288</td>\n",
       "      <td>31.404495</td>\n",
       "      <td>...</td>\n",
       "      <td>34695</td>\n",
       "      <td>7480</td>\n",
       "      <td>58270</td>\n",
       "      <td>30.859953</td>\n",
       "      <td>30.938112</td>\n",
       "      <td>32.053539</td>\n",
       "      <td>31.498846</td>\n",
       "      <td>31.262012</td>\n",
       "      <td>32.050858</td>\n",
       "      <td>31.744798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>29997</td>\n",
       "      <td>55.309746</td>\n",
       "      <td>53.856491</td>\n",
       "      <td>55.245605</td>\n",
       "      <td>55.156731</td>\n",
       "      <td>55.386330</td>\n",
       "      <td>55.594093</td>\n",
       "      <td>55.457638</td>\n",
       "      <td>55.631950</td>\n",
       "      <td>55.001411</td>\n",
       "      <td>...</td>\n",
       "      <td>55150</td>\n",
       "      <td>12209</td>\n",
       "      <td>53677</td>\n",
       "      <td>53.447701</td>\n",
       "      <td>54.243759</td>\n",
       "      <td>54.131619</td>\n",
       "      <td>55.441936</td>\n",
       "      <td>54.554523</td>\n",
       "      <td>54.286480</td>\n",
       "      <td>54.389249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>29998</td>\n",
       "      <td>61.431679</td>\n",
       "      <td>61.042538</td>\n",
       "      <td>61.438362</td>\n",
       "      <td>61.994614</td>\n",
       "      <td>61.362617</td>\n",
       "      <td>62.571304</td>\n",
       "      <td>61.454952</td>\n",
       "      <td>61.281811</td>\n",
       "      <td>61.259480</td>\n",
       "      <td>...</td>\n",
       "      <td>54106</td>\n",
       "      <td>12456</td>\n",
       "      <td>53412</td>\n",
       "      <td>61.059872</td>\n",
       "      <td>60.931667</td>\n",
       "      <td>61.399853</td>\n",
       "      <td>61.751053</td>\n",
       "      <td>62.483074</td>\n",
       "      <td>61.677982</td>\n",
       "      <td>61.683299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>29999</td>\n",
       "      <td>4.966510</td>\n",
       "      <td>4.951837</td>\n",
       "      <td>4.872506</td>\n",
       "      <td>4.947905</td>\n",
       "      <td>4.836755</td>\n",
       "      <td>4.822618</td>\n",
       "      <td>4.945584</td>\n",
       "      <td>4.762985</td>\n",
       "      <td>4.751533</td>\n",
       "      <td>...</td>\n",
       "      <td>7211</td>\n",
       "      <td>1425</td>\n",
       "      <td>64164</td>\n",
       "      <td>4.935795</td>\n",
       "      <td>4.967635</td>\n",
       "      <td>5.335175</td>\n",
       "      <td>4.839327</td>\n",
       "      <td>4.896451</td>\n",
       "      <td>4.940805</td>\n",
       "      <td>4.951068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>30000</td>\n",
       "      <td>31.009163</td>\n",
       "      <td>31.666092</td>\n",
       "      <td>31.163036</td>\n",
       "      <td>30.777660</td>\n",
       "      <td>31.084269</td>\n",
       "      <td>31.125706</td>\n",
       "      <td>31.279673</td>\n",
       "      <td>30.877525</td>\n",
       "      <td>30.829874</td>\n",
       "      <td>...</td>\n",
       "      <td>33782</td>\n",
       "      <td>7270</td>\n",
       "      <td>58458</td>\n",
       "      <td>31.519632</td>\n",
       "      <td>31.590820</td>\n",
       "      <td>31.971601</td>\n",
       "      <td>31.213898</td>\n",
       "      <td>31.721998</td>\n",
       "      <td>31.768383</td>\n",
       "      <td>31.334736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id          1          2          3          4          5          6  \\\n",
       "0     25001   2.078502   2.048270   2.176548   2.181710   2.171663   2.042809   \n",
       "1     25002  47.102856  47.471851  47.402054  47.428837  46.916428  46.533054   \n",
       "2     25003  63.601151  63.744083  63.498966  64.263016  63.850052  63.831371   \n",
       "3     25004   3.402958   3.249214   3.299937   3.176938   3.356996   3.380183   \n",
       "4     25005  44.893665  45.110535  44.781345  44.324539  44.479763  44.815819   \n",
       "...     ...        ...        ...        ...        ...        ...        ...   \n",
       "4995  29996  31.803255  31.420254  31.000479  31.894354  32.291943  31.517700   \n",
       "4996  29997  55.309746  53.856491  55.245605  55.156731  55.386330  55.594093   \n",
       "4997  29998  61.431679  61.042538  61.438362  61.994614  61.362617  62.571304   \n",
       "4998  29999   4.966510   4.951837   4.872506   4.947905   4.836755   4.822618   \n",
       "4999  30000  31.009163  31.666092  31.163036  30.777660  31.084269  31.125706   \n",
       "\n",
       "              7          8          9  ...     f1     f2     f3         13  \\\n",
       "0      2.054140   2.218273   1.979649  ...   2868    499  65050   2.013689   \n",
       "1     47.178307  46.916542  46.560528  ...  47019  10977  54836  47.192917   \n",
       "2     63.330708  63.916481  64.481827  ...  55200  12753  53104  63.066990   \n",
       "3      3.544874   3.205535   3.324197  ...   3705    627  64924   3.014899   \n",
       "4     44.842922  44.496338  44.447712  ...  45646  10110  55722  44.922932   \n",
       "...         ...        ...        ...  ...    ...    ...    ...        ...   \n",
       "4995  31.811995  31.809288  31.404495  ...  34695   7480  58270  30.859953   \n",
       "4996  55.457638  55.631950  55.001411  ...  55150  12209  53677  53.447701   \n",
       "4997  61.454952  61.281811  61.259480  ...  54106  12456  53412  61.059872   \n",
       "4998   4.945584   4.762985   4.751533  ...   7211   1425  64164   4.935795   \n",
       "4999  31.279673  30.877525  30.829874  ...  33782   7270  58458  31.519632   \n",
       "\n",
       "             14         15         16         17         18  clip_count  \n",
       "0      2.107004   2.010603   2.404801   2.069614   2.198115    2.072007  \n",
       "1     46.937836  47.383320  47.509872  48.650318  48.066029   47.003592  \n",
       "2     63.650635  63.486897  63.994404  63.896095  63.706322   64.066205  \n",
       "3      3.257248   3.233060   3.069120   3.185067   3.282437    3.334631  \n",
       "4     45.427040  45.568714  43.645378  44.773441  45.163376   44.903638  \n",
       "...         ...        ...        ...        ...        ...         ...  \n",
       "4995  30.938112  32.053539  31.498846  31.262012  32.050858   31.744798  \n",
       "4996  54.243759  54.131619  55.441936  54.554523  54.286480   54.389249  \n",
       "4997  60.931667  61.399853  61.751053  62.483074  61.677982   61.683299  \n",
       "4998   4.967635   5.335175   4.839327   4.896451   4.940805    4.951068  \n",
       "4999  31.590820  31.971601  31.213898  31.721998  31.768383   31.334736  \n",
       "\n",
       "[5000 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\"\"\"MSE=[]\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test=train_test_split(test.iloc[:,:-1],\n",
    "                                                      test.iloc[:,-1],\n",
    "                                                      test_size=0.2)\n",
    "\n",
    "    model=LinearRegression().fit(X_train, y_train)\n",
    "    pred=model.predict(X_test)\n",
    "    MSE.append(mean_squared_error(pred,y_test.values))\n",
    "    print(MSE[-1])\n",
    "    np.array(MSE).mean()\"\"\"\n",
    "\n",
    "test=pd.read_csv(\"/notebooks/test.csv\")\n",
    "model=LinearRegression().fit(test.drop([\"id\",\"TRUE\"],axis=1),test[\"TRUE\"])\n",
    "df=pd.read_csv(\"/notebooks/final.csv\")\n",
    "df[\"clip_count\"]=model.predict(df.iloc[:,1:])\n",
    "df[[\"id\",\"clip_count\"]].to_csv(\"/notebooks/submit_LRG.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45001</td>\n",
       "      <td>66.483871</td>\n",
       "      <td>68.247749</td>\n",
       "      <td>66.648193</td>\n",
       "      <td>67.212799</td>\n",
       "      <td>66.653748</td>\n",
       "      <td>67.263458</td>\n",
       "      <td>67.051575</td>\n",
       "      <td>67.126739</td>\n",
       "      <td>66.983757</td>\n",
       "      <td>...</td>\n",
       "      <td>61355</td>\n",
       "      <td>14280</td>\n",
       "      <td>51635</td>\n",
       "      <td>68</td>\n",
       "      <td>67.068939</td>\n",
       "      <td>67.058807</td>\n",
       "      <td>68.732140</td>\n",
       "      <td>66.852257</td>\n",
       "      <td>67.853073</td>\n",
       "      <td>68.737343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45002</td>\n",
       "      <td>40.468941</td>\n",
       "      <td>40.110317</td>\n",
       "      <td>40.656063</td>\n",
       "      <td>40.764927</td>\n",
       "      <td>40.876328</td>\n",
       "      <td>40.335373</td>\n",
       "      <td>40.375340</td>\n",
       "      <td>40.574928</td>\n",
       "      <td>40.583611</td>\n",
       "      <td>...</td>\n",
       "      <td>40761</td>\n",
       "      <td>9209</td>\n",
       "      <td>56548</td>\n",
       "      <td>40</td>\n",
       "      <td>40.513443</td>\n",
       "      <td>40.126709</td>\n",
       "      <td>40.082539</td>\n",
       "      <td>40.168465</td>\n",
       "      <td>40.051807</td>\n",
       "      <td>40.884926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45003</td>\n",
       "      <td>41.460964</td>\n",
       "      <td>41.237000</td>\n",
       "      <td>41.067108</td>\n",
       "      <td>41.374786</td>\n",
       "      <td>41.528965</td>\n",
       "      <td>41.465656</td>\n",
       "      <td>41.205536</td>\n",
       "      <td>41.467598</td>\n",
       "      <td>41.903027</td>\n",
       "      <td>...</td>\n",
       "      <td>45467</td>\n",
       "      <td>9829</td>\n",
       "      <td>55936</td>\n",
       "      <td>41</td>\n",
       "      <td>40.529606</td>\n",
       "      <td>41.791656</td>\n",
       "      <td>42.395710</td>\n",
       "      <td>41.541862</td>\n",
       "      <td>41.879608</td>\n",
       "      <td>42.029758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45004</td>\n",
       "      <td>38.751732</td>\n",
       "      <td>38.798252</td>\n",
       "      <td>38.221867</td>\n",
       "      <td>38.272499</td>\n",
       "      <td>38.189594</td>\n",
       "      <td>38.107555</td>\n",
       "      <td>38.276199</td>\n",
       "      <td>37.992920</td>\n",
       "      <td>38.329498</td>\n",
       "      <td>...</td>\n",
       "      <td>37876</td>\n",
       "      <td>8451</td>\n",
       "      <td>57317</td>\n",
       "      <td>39</td>\n",
       "      <td>38.873005</td>\n",
       "      <td>38.273144</td>\n",
       "      <td>39.530891</td>\n",
       "      <td>38.209827</td>\n",
       "      <td>37.762806</td>\n",
       "      <td>38.366428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45005</td>\n",
       "      <td>17.631557</td>\n",
       "      <td>18.474697</td>\n",
       "      <td>17.742939</td>\n",
       "      <td>17.419392</td>\n",
       "      <td>17.760508</td>\n",
       "      <td>17.705917</td>\n",
       "      <td>17.507004</td>\n",
       "      <td>17.828539</td>\n",
       "      <td>17.556057</td>\n",
       "      <td>...</td>\n",
       "      <td>18560</td>\n",
       "      <td>3932</td>\n",
       "      <td>61734</td>\n",
       "      <td>19</td>\n",
       "      <td>18.065754</td>\n",
       "      <td>18.086224</td>\n",
       "      <td>18.998547</td>\n",
       "      <td>17.480804</td>\n",
       "      <td>17.940041</td>\n",
       "      <td>18.797537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>49996</td>\n",
       "      <td>35.934433</td>\n",
       "      <td>35.309082</td>\n",
       "      <td>35.609249</td>\n",
       "      <td>35.316940</td>\n",
       "      <td>35.871963</td>\n",
       "      <td>35.322407</td>\n",
       "      <td>35.144230</td>\n",
       "      <td>35.696674</td>\n",
       "      <td>35.814716</td>\n",
       "      <td>...</td>\n",
       "      <td>35775</td>\n",
       "      <td>7886</td>\n",
       "      <td>57833</td>\n",
       "      <td>35</td>\n",
       "      <td>35.250870</td>\n",
       "      <td>35.313862</td>\n",
       "      <td>35.307575</td>\n",
       "      <td>35.863522</td>\n",
       "      <td>35.563389</td>\n",
       "      <td>36.225704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>49997</td>\n",
       "      <td>54.239372</td>\n",
       "      <td>53.150887</td>\n",
       "      <td>53.655266</td>\n",
       "      <td>54.484295</td>\n",
       "      <td>53.709156</td>\n",
       "      <td>54.309490</td>\n",
       "      <td>53.896324</td>\n",
       "      <td>54.291805</td>\n",
       "      <td>54.020184</td>\n",
       "      <td>...</td>\n",
       "      <td>50962</td>\n",
       "      <td>11382</td>\n",
       "      <td>54432</td>\n",
       "      <td>54</td>\n",
       "      <td>53.494812</td>\n",
       "      <td>53.149113</td>\n",
       "      <td>53.200169</td>\n",
       "      <td>53.131248</td>\n",
       "      <td>54.002472</td>\n",
       "      <td>54.264385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>49998</td>\n",
       "      <td>71.145584</td>\n",
       "      <td>71.147865</td>\n",
       "      <td>70.953239</td>\n",
       "      <td>71.699875</td>\n",
       "      <td>71.459007</td>\n",
       "      <td>70.983078</td>\n",
       "      <td>70.717415</td>\n",
       "      <td>71.407021</td>\n",
       "      <td>71.009995</td>\n",
       "      <td>...</td>\n",
       "      <td>63938</td>\n",
       "      <td>15244</td>\n",
       "      <td>50704</td>\n",
       "      <td>72</td>\n",
       "      <td>70.673981</td>\n",
       "      <td>70.489418</td>\n",
       "      <td>71.557632</td>\n",
       "      <td>72.032745</td>\n",
       "      <td>71.640343</td>\n",
       "      <td>71.700966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>49999</td>\n",
       "      <td>23.010813</td>\n",
       "      <td>23.043373</td>\n",
       "      <td>22.641993</td>\n",
       "      <td>22.648394</td>\n",
       "      <td>22.773958</td>\n",
       "      <td>22.792301</td>\n",
       "      <td>22.843092</td>\n",
       "      <td>22.701715</td>\n",
       "      <td>22.557844</td>\n",
       "      <td>...</td>\n",
       "      <td>24989</td>\n",
       "      <td>5269</td>\n",
       "      <td>60416</td>\n",
       "      <td>24</td>\n",
       "      <td>22.766565</td>\n",
       "      <td>22.996029</td>\n",
       "      <td>23.217543</td>\n",
       "      <td>22.926369</td>\n",
       "      <td>23.010355</td>\n",
       "      <td>23.527931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>50000</td>\n",
       "      <td>34.556046</td>\n",
       "      <td>35.664646</td>\n",
       "      <td>35.190777</td>\n",
       "      <td>35.082882</td>\n",
       "      <td>35.097263</td>\n",
       "      <td>34.860394</td>\n",
       "      <td>35.143150</td>\n",
       "      <td>35.102570</td>\n",
       "      <td>34.925900</td>\n",
       "      <td>...</td>\n",
       "      <td>36861</td>\n",
       "      <td>8409</td>\n",
       "      <td>57366</td>\n",
       "      <td>35</td>\n",
       "      <td>35.189098</td>\n",
       "      <td>35.525414</td>\n",
       "      <td>35.390224</td>\n",
       "      <td>34.931408</td>\n",
       "      <td>35.754185</td>\n",
       "      <td>36.400433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id          1          2          3          4          5          6  \\\n",
       "0     45001  66.483871  68.247749  66.648193  67.212799  66.653748  67.263458   \n",
       "1     45002  40.468941  40.110317  40.656063  40.764927  40.876328  40.335373   \n",
       "2     45003  41.460964  41.237000  41.067108  41.374786  41.528965  41.465656   \n",
       "3     45004  38.751732  38.798252  38.221867  38.272499  38.189594  38.107555   \n",
       "4     45005  17.631557  18.474697  17.742939  17.419392  17.760508  17.705917   \n",
       "...     ...        ...        ...        ...        ...        ...        ...   \n",
       "4995  49996  35.934433  35.309082  35.609249  35.316940  35.871963  35.322407   \n",
       "4996  49997  54.239372  53.150887  53.655266  54.484295  53.709156  54.309490   \n",
       "4997  49998  71.145584  71.147865  70.953239  71.699875  71.459007  70.983078   \n",
       "4998  49999  23.010813  23.043373  22.641993  22.648394  22.773958  22.792301   \n",
       "4999  50000  34.556046  35.664646  35.190777  35.082882  35.097263  34.860394   \n",
       "\n",
       "              7          8          9  ...     f1     f2     f3  TRUE  \\\n",
       "0     67.051575  67.126739  66.983757  ...  61355  14280  51635    68   \n",
       "1     40.375340  40.574928  40.583611  ...  40761   9209  56548    40   \n",
       "2     41.205536  41.467598  41.903027  ...  45467   9829  55936    41   \n",
       "3     38.276199  37.992920  38.329498  ...  37876   8451  57317    39   \n",
       "4     17.507004  17.828539  17.556057  ...  18560   3932  61734    19   \n",
       "...         ...        ...        ...  ...    ...    ...    ...   ...   \n",
       "4995  35.144230  35.696674  35.814716  ...  35775   7886  57833    35   \n",
       "4996  53.896324  54.291805  54.020184  ...  50962  11382  54432    54   \n",
       "4997  70.717415  71.407021  71.009995  ...  63938  15244  50704    72   \n",
       "4998  22.843092  22.701715  22.557844  ...  24989   5269  60416    24   \n",
       "4999  35.143150  35.102570  34.925900  ...  36861   8409  57366    35   \n",
       "\n",
       "             13         14         15         16         17         18  \n",
       "0     67.068939  67.058807  68.732140  66.852257  67.853073  68.737343  \n",
       "1     40.513443  40.126709  40.082539  40.168465  40.051807  40.884926  \n",
       "2     40.529606  41.791656  42.395710  41.541862  41.879608  42.029758  \n",
       "3     38.873005  38.273144  39.530891  38.209827  37.762806  38.366428  \n",
       "4     18.065754  18.086224  18.998547  17.480804  17.940041  18.797537  \n",
       "...         ...        ...        ...        ...        ...        ...  \n",
       "4995  35.250870  35.313862  35.307575  35.863522  35.563389  36.225704  \n",
       "4996  53.494812  53.149113  53.200169  53.131248  54.002472  54.264385  \n",
       "4997  70.673981  70.489418  71.557632  72.032745  71.640343  71.700966  \n",
       "4998  22.766565  22.996029  23.217543  22.926369  23.010355  23.527931  \n",
       "4999  35.189098  35.525414  35.390224  34.931408  35.754185  36.400433  \n",
       "\n",
       "[5000 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Majority Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>clip_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25001.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25002.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25003.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25004.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25005.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>29996.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>29997.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>29998.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>29999.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id     1     2     3     4     5     6     7     8     9    10  \\\n",
       "0     25001.0   2.0   2.0   2.0   2.0   2.0   2.0   2.0   2.0   2.0   2.0   \n",
       "1     25002.0  47.0  47.0  47.0  47.0  47.0  47.0  47.0  47.0  47.0  47.0   \n",
       "2     25003.0  64.0  64.0  63.0  64.0  64.0  64.0  63.0  64.0  64.0  65.0   \n",
       "3     25004.0   3.0   3.0   3.0   3.0   3.0   3.0   4.0   3.0   3.0   3.0   \n",
       "4     25005.0  45.0  45.0  45.0  44.0  44.0  45.0  45.0  44.0  44.0  45.0   \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "4995  29996.0  32.0  31.0  31.0  32.0  32.0  32.0  32.0  32.0  31.0  32.0   \n",
       "4996  29997.0  55.0  54.0  55.0  55.0  55.0  56.0  55.0  56.0  55.0  55.0   \n",
       "4997  29998.0  61.0  61.0  61.0  62.0  61.0  63.0  61.0  61.0  61.0  62.0   \n",
       "4998  29999.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   \n",
       "4999  30000.0  31.0  32.0  31.0  31.0  31.0  31.0  31.0  31.0  31.0  31.0   \n",
       "\n",
       "        11    12  clip_count  \n",
       "0      2.0   2.0         2.0  \n",
       "1     47.0  47.0        47.0  \n",
       "2     63.0  64.0        64.0  \n",
       "3      3.0   3.0         3.0  \n",
       "4     44.0  45.0        45.0  \n",
       "...    ...   ...         ...  \n",
       "4995  32.0  32.0        32.0  \n",
       "4996  55.0  55.0        55.0  \n",
       "4997  62.0  62.0        61.0  \n",
       "4998   5.0   5.0         5.0  \n",
       "4999  30.0  31.0        31.0  \n",
       "\n",
       "[5000 rows x 14 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "df=pd.read_csv(\"/notebooks/final.csv\")\n",
    "#df[\"True\"]=pd.read_csv(\"/notebooks/storage/data.csv\")[-5000:][\"clip_count\"].values\n",
    "df.iloc[:,1:]=df.iloc[:,1:].applymap(lambda x: np.round(x))\n",
    "df[\"clip_count\"]=df.iloc[:,1:].apply(lambda x:mode(x)[0][0],axis=1)\n",
    "df.iloc[:,[0,-1]].to_csv(\"/notebooks/submit_MJV.csv\")\n",
    "df\n",
    "#This is for test validation\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#mean_squared_error(df[\"clip_count\"].values,df[\"True\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n"
     ]
    },
    {
     "ename": "H2OStartupError",
     "evalue": "Cannot find Java. Please install the latest JRE from\nhttp://www.oracle.com/technetwork/java/javase/downloads/index.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mH2OConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h2o/h2o.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(url, ip, port, name, https, cacert, insecure, username, password, cookies, proxy, start_h2o, nthreads, ice_root, log_dir, log_level, max_log_file_size, enable_assertions, max_mem_size, min_mem_size, strict_version_check, ignore_config, extra_classpath, jvm_custom_args, bind_to_localhost, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m                                      _msgs=(\"Checking whether there is an H2O instance running at {url} \",\n\u001b[0;32m--> 289\u001b[0;31m                                             \"connected.\", \"not found.\"))\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mH2OConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(server, url, ip, port, name, https, auth, verify_ssl_certificates, cacert, proxy, cookies, verbose, _msgs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0;31m# If a server is unable to respond within 1s, it should be considered a bug. However we disable this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36m_test_connection\u001b[0;34m(self, max_retries, messages)\u001b[0m\n\u001b[1;32m    683\u001b[0m             raise H2OConnectionError(\"Could not establish link to the H2O cloud %s after %d retries\\n%s\"\n\u001b[0;32m--> 684\u001b[0;31m                                      % (self._base_url, max_retries, \"\\n\".join(errors)))\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mH2OConnectionError\u001b[0m: Could not establish link to the H2O cloud http://localhost:54321 after 5 retries\n[43:00.43] H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='localhost', port=54321): Max retries exceeded with url: /3/Cloud (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd767b51f98>: Failed to establish a new connection: [Errno 111] Connection refused',))\n[43:00.64] H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='localhost', port=54321): Max retries exceeded with url: /3/Cloud (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd767b6c710>: Failed to establish a new connection: [Errno 111] Connection refused',))\n[43:00.84] H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='localhost', port=54321): Max retries exceeded with url: /3/Cloud (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd767b6cdd8>: Failed to establish a new connection: [Errno 111] Connection refused',))\n[43:01.05] H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='localhost', port=54321): Max retries exceeded with url: /3/Cloud (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd767b7e4e0>: Failed to establish a new connection: [Errno 111] Connection refused',))\n[43:01.25] H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='localhost', port=54321): Max retries exceeded with url: /3/Cloud (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd767b7eba8>: Failed to establish a new connection: [Errno 111] Connection refused',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mH2OStartupError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-329517c717b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mH2OAutoML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h2o/h2o.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(url, ip, port, name, https, cacert, insecure, username, password, cookies, proxy, start_h2o, nthreads, ice_root, log_dir, log_level, max_log_file_size, enable_assertions, max_mem_size, min_mem_size, strict_version_check, ignore_config, extra_classpath, jvm_custom_args, bind_to_localhost, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m                                   \u001b[0mmax_log_file_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_log_file_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                                   \u001b[0mextra_classpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextra_classpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjvm_custom_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjvm_custom_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m                                   bind_to_localhost=bind_to_localhost)\n\u001b[0m\u001b[1;32m    302\u001b[0m         h2oconn = H2OConnection.open(server=hs, https=https, verify_ssl_certificates=verify_ssl_certificates,\n\u001b[1;32m    303\u001b[0m                                      cacert=cacert, auth=auth, proxy=proxy,cookies=cookies, verbose=True)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h2o/backend/server.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(jar_path, nthreads, enable_assertions, max_mem_size, min_mem_size, ice_root, log_dir, log_level, max_log_file_size, port, name, extra_classpath, verbose, jvm_custom_args, bind_to_localhost)\u001b[0m\n\u001b[1;32m    141\u001b[0m         hs._launch_server(port=port, baseport=baseport, nthreads=int(nthreads), ea=enable_assertions,\n\u001b[1;32m    142\u001b[0m                           \u001b[0mmmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_mem_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_mem_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjvm_custom_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjvm_custom_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                           bind_to_localhost=bind_to_localhost, log_dir=log_dir, log_level=log_level, max_log_file_size=max_log_file_size)\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Server is running at %s://%s:%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h2o/backend/server.py\u001b[0m in \u001b[0;36m_launch_server\u001b[0;34m(self, port, baseport, mmax, mmin, ea, nthreads, jvm_custom_args, bind_to_localhost, log_dir, log_level, max_log_file_size)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# Find Java and check version. (Note that subprocess.check_output returns the output as a bytes object)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mjava\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h2o/backend/server.py\u001b[0m in \u001b[0;36m_find_java\u001b[0;34m()\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# not found...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         raise H2OStartupError(\"Cannot find Java. Please install the latest JRE from\\n\"\n\u001b[0m\u001b[1;32m    442\u001b[0m                               \"http://www.oracle.com/technetwork/java/javase/downloads/index.html\")\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mH2OStartupError\u001b[0m: Cannot find Java. Please install the latest JRE from\nhttp://www.oracle.com/technetwork/java/javase/downloads/index.html"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test=pd.read_csv(\"/notebooks/test.csv\")\n",
    "test.set_index(\"id\",inplace=True)\n",
    "test[\"True\"]=pd.read_csv(\"/notebooks/storage/data.csv\")[-5000:][\"clip_count\"].values\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "h2o.init()\n",
    "import random\n",
    "train=test.iloc[random.sample(range(5000),4000),:]\n",
    "mask=test.index.isin(train.index)\n",
    "test=test.loc[(1-mask).astype(bool),:]\n",
    "x=train.columns[:-1]\n",
    "y=train.columns[-1]\n",
    "\n",
    "aml = H2OAutoML(max_models=20, seed=1)\n",
    "aml.train(x=x, y=y, training_frame=train)\n",
    "preds = aml.predict(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"/notebooks/final.csv\")\n",
    "df[\"clip_count\"]=df.iloc[:,1:].apply(lambda x:x.mean(),axis=1)\n",
    "df[[\"id\",\"clip_count\"]].to_csv(\"/notebooks/submit_GAG.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=8)]: Done 5000 out of 5000 | elapsed:   20.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=5, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=5000,\n",
       "                       n_jobs=8, oob_score=False, random_state=None, verbose=1,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(test.iloc[:,2:-1],\n",
    "                                                  test.iloc[:,-1],\n",
    "                                                  test_size=0.1)\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=5000,max_depth=5,verbose=1,n_jobs=8)\n",
    "rf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=8)]: Done 5000 out of 5000 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.718"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred=rf.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "display(mean_squared_error(pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 12 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [04:01<00:00, 20.68it/s]\n",
      "100%|██████████| 5000/5000 [04:05<00:00, 20.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [03:47<00:00, 21.95it/s]\n",
      "100%|██████████| 5000/5000 [03:43<00:00, 22.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [03:46<00:00, 22.11it/s]  \n",
      "100%|██████████| 5000/5000 [03:50<00:00, 21.68it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 1541/5000 [01:07<02:31, 22.87it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-06f4ff2f61b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/storage/clips/clips-{i}.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m45001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    607\u001b[0m   \u001b[0;31m# As a fallback for the data type that does not work with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m   \u001b[0;31m# _standardize_user_data, use the _prepare_model_with_inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;31m# trigger the next permutation. On the other hand, too many simultaneous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# shuffles can contend on a hardware level and degrade all performance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     \"\"\"\n\u001b[1;32m   1210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3421\u001b[0m         \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3422\u001b[0m         \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3423\u001b[0;31m         **self._flat_structure)\n\u001b[0m\u001b[1;32m   3424\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMapDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmap_dataset\u001b[0;34m(input_dataset, other_arguments, f, output_types, output_shapes, use_inter_op_parallelism, preserve_cardinality, name)\u001b[0m\n\u001b[1;32m   2982\u001b[0m         \u001b[0;34m\"output_shapes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_inter_op_parallelism\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2983\u001b[0m         \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"preserve_cardinality\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2984\u001b[0;31m         preserve_cardinality)\n\u001b[0m\u001b[1;32m   2985\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2986\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_list=[]\n",
    "for file in os.listdir(\"/storage\"):\n",
    "    if \"0.6\" in file or \"0.7\" in file or \"0.8\" in file:\n",
    "        model_list.append(file)\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "count=16\n",
    "final=pd.read_csv(\"/notebooks/final.csv\")\n",
    "test=pd.read_csv(\"/notebooks/test.csv\")\n",
    "for file in model_list[3:]:\n",
    "    model=load_model(f\"/storage/{file}\",compile=False)\n",
    "    model.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n",
    "    \n",
    "    for i in tqdm(range(25001,30001)):\n",
    "        arr=np.expand_dims(np.array(Image.open(f\"/storage/clips/clips-{i}.png\"))/255, 0)\n",
    "        final.loc[i,str(count)]=model.predict(arr)[0,0]\n",
    "    \n",
    "    for i in tqdm(range(45001,50001)):\n",
    "        arr=np.expand_dims(np.array(Image.open(f\"/storage/clips/clips-{i}.png\"))/255, 0)\n",
    "        test.loc[i,str(count)]=model.predict(arr)[0,0]\n",
    "        \n",
    "    final[str(count)]=final[str(count)].apply(lambda x: 75 if x>75 else x)\n",
    "    test[str(count)]=test[str(count)].apply(lambda x: 75 if x>75 else x)\n",
    "\n",
    "    final.to_csv(\"/notebooks/final.csv\")\n",
    "    test.to_csv(\"/notebooks/test.csv\")\n",
    "    print(f\"{count} done.\")\n",
    "    count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
